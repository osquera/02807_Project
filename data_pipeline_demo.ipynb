{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d57e5ac3",
   "metadata": {},
   "source": [
    "# Rotten Tomatoes Movie Data Pipeline Demo\n",
    "\n",
    "This notebook demonstrates the complete data acquisition and cleaning pipeline for the Rotten Tomatoes movie analysis project. We'll use the automated task system to download datasets, clean the data, and scrape additional movie information from Rotten Tomatoes.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project analyzes movie reviews and ratings data from Rotten Tomatoes, combining:\n",
    "- **Kaggle Dataset**: Movie critic reviews and ratings\n",
    "- **Web Scraping**: Additional movie details (titles, descriptions, release years) from Rotten Tomatoes website\n",
    "\n",
    "## Data Pipeline Steps\n",
    "\n",
    "1. **Environment Setup**: Install dependencies and verify setup\n",
    "2. **Data Download**: Download raw datasets from Kaggle\n",
    "3. **Data Cleaning**: Clean and validate the downloaded data\n",
    "4. **Web Scraping**: Scrape additional movie details from Rotten Tomatoes\n",
    "5. **Data Exploration**: Validate and explore the final cleaned datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4050e79f",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's verify that our environment is properly set up and all dependencies are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d2f120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.8 (main, Jan 14 2025, 22:49:36) [MSC v.1942 64 bit (AMD64)]\n",
      "Current working directory: C:\\Users\\anton\\AppData\\Roaming\\uv\\python\\cpython-3.12.8-windows-x86_64-none\\python312.zip\n",
      "‚úÖ Core data packages available\n",
      "‚úÖ Core data packages available\n"
     ]
    }
   ],
   "source": [
    "# Check Python version and environment\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Current working directory: {sys.path[0]}\")\n",
    "\n",
    "# Verify required packages are available\n",
    "try:\n",
    "    import polars as pl\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    print(\"‚úÖ Core data packages available\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Missing packages: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f9c3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m114 packages\u001b[0m \u001b[2min 2.11s\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m110 packages\u001b[0m \u001b[2min 273ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Sync dependencies using uv\n",
    "!uv sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8631d93d",
   "metadata": {},
   "source": [
    "## 2. Data Download\n",
    "\n",
    "Now let's download the raw datasets from Kaggle. This includes the Rotten Tomatoes critic reviews dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c66795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mtask: [sync] uv sync\n",
      "\u001b[0m\u001b[2mResolved \u001b[1m114 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m110 packages\u001b[0m \u001b[2min 10ms\u001b[0m\u001b[0m\n",
      "\u001b[32mtask: [download-data] uv run python src/02807_project/data_loader.py\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Download datasets from Kaggle\n",
    "# This will download and save the Rotten Tomatoes datasets locally\n",
    "!task download-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d55c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify downloaded data\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"data/raw\")\n",
    "if data_dir.exists():\n",
    "    files = list(data_dir.glob(\"*.csv\"))\n",
    "    print(f\"üìÅ Found {len(files)} CSV files in {data_dir}:\")\n",
    "    for file in files:\n",
    "        size = file.stat().st_size / 1024 / 1024  # Size in MB\n",
    "        print(\".2f\")\n",
    "else:\n",
    "    print(\"‚ùå Data directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b667371c",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning\n",
    "\n",
    "Next, let's clean the downloaded data by removing null values, invalid ratings, and standardizing the format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a70dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the downloaded datasets\n",
    "# This removes nulls, invalid ratings, and maps review scores to numeric values\n",
    "!task clean-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e098d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick exploration of cleaned data\n",
    "cleaned_files = list(Path(\"data/clean\").glob(\"*.csv\"))\n",
    "if cleaned_files:\n",
    "    print(f\"üìÅ Cleaned datasets available:\")\n",
    "    for file in cleaned_files:\n",
    "        df = pl.read_csv(file)\n",
    "        print(f\"\\nüìä {file.name}:\")\n",
    "        print(f\"   Rows: {len(df):,}\")\n",
    "        print(f\"   Columns: {len(df.columns)}\")\n",
    "        print(f\"   Columns: {', '.join(df.columns)}\")\n",
    "else:\n",
    "    print(\"‚ùå No cleaned data files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80dff3",
   "metadata": {},
   "source": [
    "## 4. Web Scraping - Rotten Tomatoes Data\n",
    "\n",
    "Now let's scrape additional movie details (titles, descriptions, release years) from Rotten Tomatoes using the movie IDs from our cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf05330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape movie details from Rotten Tomatoes\n",
    "# This will scrape titles, descriptions, and release years for movies in our dataset\n",
    "# Note: This may take several minutes depending on the number of movies\n",
    "!task scrape-rt-movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c44db7",
   "metadata": {},
   "source": [
    "## 5. Handling Failed Scrapes\n",
    "\n",
    "If some movies failed to scrape (due to network issues, rate limiting, etc.), we can retry them specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c361ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for failed scrapes and retry them\n",
    "# This will only re-scrape movies that failed in the previous attempt\n",
    "# Note: Run this only if you suspect some scrapes failed\n",
    "!task retry-failed-scrapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d30ff4",
   "metadata": {},
   "source": [
    "## 6. Final Data Exploration\n",
    "\n",
    "Let's explore our complete dataset including the scraped Rotten Tomatoes data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3246b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore all datasets (raw and cleaned)\n",
    "# This provides comprehensive statistics and summaries\n",
    "!task explore-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4ba99b",
   "metadata": {},
   "source": [
    "## 7. Summary and Next Steps\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "‚úÖ **Environment Setup**: Verified Python environment and installed dependencies\n",
    "‚úÖ **Data Download**: Downloaded Rotten Tomatoes datasets from Kaggle\n",
    "‚úÖ **Data Cleaning**: Cleaned data by removing nulls and standardizing formats\n",
    "‚úÖ **Web Scraping**: Scraped additional movie details from Rotten Tomatoes\n",
    "‚úÖ **Error Handling**: Implemented retry logic for failed scrapes\n",
    "‚úÖ **Data Exploration**: Validated and explored the final datasets\n",
    "\n",
    "### Available Data Files\n",
    "\n",
    "After running this pipeline, you'll have:\n",
    "\n",
    "- `data/raw/rotten_tomatoes_movies.csv` - Raw movie data from Kaggle\n",
    "- `data/raw/rotten_tomatoes_critic_reviews.csv` - Raw critic reviews from Kaggle\n",
    "- `data/clean/rotten_tomatoes_movies_clean.csv` - Cleaned movie data\n",
    "- `data/clean/rotten_tomatoes_critic_reviews_clean.csv` - Cleaned critic reviews\n",
    "- `data/raw/rotten_tomatoes_movie_details.csv` - Scraped movie details (titles, descriptions, years)\n",
    "\n",
    "### Quick Pipeline Command\n",
    "\n",
    "For future runs, you can use the complete pipeline in one command:\n",
    "```bash\n",
    "task setup-data\n",
    "```\n",
    "\n",
    "This runs: sync ‚Üí download-data ‚Üí clean-data all in sequence.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "With your data ready, you can now:\n",
    "- Perform sentiment analysis on critic reviews\n",
    "- Analyze the relationship between critic scores and audience ratings\n",
    "- Build recommendation models based on movie features\n",
    "- Visualize trends in movie ratings over time\n",
    "\n",
    "Happy analyzing! üé¨üìä"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02807_Project (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
